{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33e8eca3",
   "metadata": {},
   "source": [
    "# About this Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd10f87f",
   "metadata": {},
   "source": [
    "The purpose of this notebook is threefold: <br> \n",
    "    1) Explore how to use the NASDAQ Data Link API <br>\n",
    "    2) Retrieve stock information packaged in the familiar JSON format <br>\n",
    "    3) Assess the data using only an economy of packages (i.e., no Pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0118140",
   "metadata": {},
   "source": [
    "Our first step is to obtain an API key for the NASDAQ site and set it as an environment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7efd2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(key='NASDAQ_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9529e742",
   "metadata": {},
   "source": [
    "Now that we have gained access to the API, we'll query the site for data from the Frankfurt Stock Exchange (FSE) for data on Carl Zeiss Meditec (AFX_X). Our query specifies not only the data we want, but also the format in which we would like to receive the data.  In this case, it's the JSON file format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09e3cbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify URL API\n",
    "url = f\"https://data.nasdaq.com/api/v3/datasets/FSE/AFX_X/data.json?api_key={API_KEY}\"\n",
    "\n",
    "# send a GET request to the API\n",
    "r = requests.get(url)\n",
    "\n",
    "# Convert the JSON file to a Python dictionary and view\n",
    "response = r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2aa35e",
   "metadata": {},
   "source": [
    "We previewed the response and saw that our first key was \"dataset_data.\"  The output remains a bit overwhelming.  Let's continue by identifying the keys with which we have to work.  We'll only examine the keys whose associated value is something other than None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dea162a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['limit', 'transform', 'column_index', 'column_names', 'start_date', 'end_date', 'frequency', 'data', 'collapse', 'order']\n"
     ]
    }
   ],
   "source": [
    "# take the first key available\n",
    "initial_key = 'dataset_data'\n",
    "\n",
    "# collect the remaining keys\n",
    "def get_keys(json_file):\n",
    "    keys = []\n",
    "    for k in json_file.keys():\n",
    "        if k not in keys:\n",
    "            keys.append(k)\n",
    "    return keys\n",
    "\n",
    "# call our function and view its output\n",
    "resp_keys = get_keys(response[initial_key])\n",
    "print(resp_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88ccbfb",
   "metadata": {},
   "source": [
    "We have a number of keys in our file.  Below, we discover what values are associated with each key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab0450bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column_names:Date\n",
      "start_date:2\n",
      "end_date:2\n",
      "frequency:d\n",
      "data:['2020-12-01', 112.2, 112.2, 111.5, 112.0, None, 51.0, 5703.0, None, None, None]\n"
     ]
    }
   ],
   "source": [
    "# cycle through keys to view output\n",
    "for entry in resp_keys:\n",
    "    if response[initial_key][entry]:\n",
    "        print(str(entry) + \":\" + str(response[initial_key][entry][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17eeb973",
   "metadata": {},
   "source": [
    "The output above indicates our file follows the expected pattern for a JSON file: a mixture of keys associated with values and keys associated with nested data structures containing values.  \n",
    "\n",
    "It looks like `column_names` are stored separately from the data they describe. We'll take the column names and pair them with a list of data points -- accessed via the aptly-named `data` key -- to see what type of data we have for each trading day in a user-friendly format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca0adf35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date : 2020-12-01\n",
      "Open : 112.2\n",
      "High : 112.2\n",
      "Low : 111.5\n",
      "Close : 112.0\n",
      "Change : None\n",
      "Traded Volume : 51.0\n",
      "Turnover : 5703.0\n",
      "Last Price of the Day : None\n",
      "Daily Traded Units : None\n",
      "Daily Turnover : None\n"
     ]
    }
   ],
   "source": [
    "columns = response['dataset_data']['column_names']\n",
    "values = response['dataset_data']['data'][0]\n",
    "zipped_file = zip(columns, values)\n",
    "for k, v in zipped_file:\n",
    "    print(k + \" : \" + str(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04214813",
   "metadata": {},
   "source": [
    "We have struck gold!  Based on the above output, we can discern the index values for each data point (e.g., date = 0, open = 1, etc).  This makes accessing individual data points easy. We can also anticipate which values are most likely to be `None`. \n",
    "\n",
    "Having a firm grasp of the structure and navigation of this JSON file better positions us to answer some questions about the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c304bbb0",
   "metadata": {},
   "source": [
    "### Tasks 1 & 2 \n",
    "##### Collect data from the Franfurt Stock Exchange, for the ticker AFX_X, for the whole year 2017 (keep in mind that the date format is YYYY-MM-DD).  Convert the returned JSON object into a Python dictionary.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a2a609",
   "metadata": {},
   "source": [
    "These tasks are most easily accomplished using a second API call with a slight adjustement to our initial request line to accomodate the dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28a6fdbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# specify URL API\n",
    "url_2017 = f\"https://data.nasdaq.com/api/v3/datasets/FSE/AFX_X/data.json?&start_date=2017-01-01&end_date=2017-12-31&api_key={API_KEY}\"\n",
    "\n",
    "# send a GET request to the API\n",
    "r = requests.get(url_2017)\n",
    "\n",
    "# Convert the JSON file to a Python dictionary and view\n",
    "response_2017 = r.json()\n",
    "print(type(response_2017))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103bba54",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "##### Calculate what the highest and lowest opening prices were for the stock in this period.\n",
    "\n",
    "Our exploration of the JSON file pays off! We know what the initial key is and how the data are packaged. Furthermore, we know that the opening prices for each day are positionally aligned at index 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41732592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Opening Price: 53.11\n",
      "Minimum Opening Price: 34.0\n"
     ]
    }
   ],
   "source": [
    "# store all open prices\n",
    "opening_prices = []\n",
    "\n",
    "# loop acress all lists in the data key (using our knowledge and initial key from above)\n",
    "for i in response_2017[initial_key]['data']:\n",
    "    if i[1] is not None:\n",
    "        opening_prices.append(i[1])\n",
    "\n",
    "# find and print answers\n",
    "max_open = max(opening_prices)\n",
    "min_open = min(opening_prices)\n",
    "print(\"Max Opening Price: \" + str(max_open) + \"\\n\" + \"Minimum Opening Price: \" + str(min_open))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c04951d",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "##### What was the largest change in any one day (based on High and Low price)?\n",
    "\n",
    "The question is a bit ambiguous, as it does not specify if we are to calculate percentage change or dollar change. Absent instructions to the contrary, we'll return the dollar change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a57eb358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The largest change in a single day based on high and low prices: $2.81.\n"
     ]
    }
   ],
   "source": [
    "highs, lows = [], []\n",
    "\n",
    "# get high and low prices for each day\n",
    "for i in response_2017[initial_key]['data']:\n",
    "    if i[2] is not None and i[3] is not None:\n",
    "        highs.append(i[2])\n",
    "        lows.append(i[3])\n",
    "\n",
    "zipped_high_low = zip(highs, lows)\n",
    "\n",
    "# set the change variable\n",
    "max_change_high_low = float(\"-inf\")\n",
    "\n",
    "# calculate the max change for a single day\n",
    "for high, low in zipped_high_low:\n",
    "    # the check for \"None\" is included once again as a fail safe measure\n",
    "    if high is not None and low is not None:\n",
    "        change_high_low = high - low\n",
    "        max_change_high_low = max(change_high_low, max_change_high_low)\n",
    "\n",
    "print(\"The largest change in a single day based on high and low prices: \" + \"$\" + str(round(max_change_high_low, 4)) + \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7e03d9",
   "metadata": {},
   "source": [
    "### Task 5\n",
    "##### What was the largest change between any two days (based on Closing Price)?\n",
    "\n",
    "The questions suffer from the same ambiguity as above, so we'll take the same approach as we did in the preceeding cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ee2b54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The largest change between any two days' closing prices: $2.56.\n"
     ]
    }
   ],
   "source": [
    "closing_prices = []\n",
    "\n",
    "# get closing prices\n",
    "for i in response_2017[initial_key]['data']:\n",
    "    if i[4] is not None:\n",
    "        closing_prices.append(i[4])\n",
    "\n",
    "# set the change variable\n",
    "max_change_closing = float(\"-inf\")\n",
    "\n",
    "# calculate the max change for a single day\n",
    "for j in range(len(closing_prices)-1):\n",
    "    if closing_prices[j] and closing_prices[j+1]:\n",
    "        change_closing = closing_prices[j+1] - closing_prices[j] \n",
    "        max_change_closing = max(change_closing, max_change_closing)\n",
    "        \n",
    "print(\"The largest change between any two days' closing prices: \" + \"$\" + str(round(max_change_closing,2)) + \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cc8466",
   "metadata": {},
   "source": [
    "### Task 6\n",
    "##### What was the average daily trading volume during this year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4ccbc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average daily trading volume in 2017: 89124.34.\n"
     ]
    }
   ],
   "source": [
    "volumes = 0\n",
    "volumes_count = 0\n",
    "# get daily trading volumes\n",
    "for i in response_2017[initial_key]['data']:\n",
    "    if i[6] is not None:\n",
    "        volumes += i[6]\n",
    "        volumes_count += 1\n",
    "avg_vol = (round(volumes/volumes_count,2))\n",
    "print(\"The average daily trading volume in 2017: \" + str(avg_vol) + \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3b51ae",
   "metadata": {},
   "source": [
    "### Task 7\n",
    "##### (Optional) What was the median trading volume during this year?\n",
    "\n",
    "This task, though optional, offers us a chance to implement a median function, which sounds interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "613f4c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The median daily trading volume in 2017: 76286.0.\n"
     ]
    }
   ],
   "source": [
    "def median(initial_key = initial_key, key = 'data', index=6):\n",
    "    res = []\n",
    "    for i in response_2017[initial_key][key]:\n",
    "        if i[index] is not None:\n",
    "            res.append(i[index])\n",
    "    res.sort()\n",
    "    median_index = len(res)//2\n",
    "    return res[median_index]\n",
    "\n",
    "med = median()\n",
    "print(\"The median daily trading volume in 2017: \" + str(med) + \".\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
